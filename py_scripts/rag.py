import json
from typing import List, TypedDict
from pydantic import BaseModel, Field
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import PromptTemplate
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import init_chat_model
from langchain import hub
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import START, END, StateGraph

model_name = "llama3-8b-8192"
def meta_func(obj: dict, seq_num: int) -> dict:
    return {
        "seq_num":            seq_num,
        "recipe_name":        obj.get("recipe_name", ""),
        "recipe_link":        obj.get("recipe_link", ""),
        "image_url":          obj.get("image_url", ""),
        "user_recipe_count":  int(obj.get("user_recipe", 0)),
        "user_fans_count":    int(obj.get("user_fans", 0)),
        "view_count":         int(obj.get("view_count", 0)),
        "like_count":         int(obj.get("like_count", 0)),
        "together_count":     int(obj.get("together_count", 0)),
        "comment_count":      int(obj.get("comment_count", 0)),
        "date":               str(obj.get("date", "")),
    }

def build_docs_from_list(path: List[dict]) -> List[Document]:
    docs = []
    for i, obj in enumerate(path):
        content_parts = [
            f"é£Ÿè­œåç¨±: {obj.get('recipe_name', '')}",
            f"æè¿°: {obj.get('description', '')}",
            f"æ¨™ç±¤: {', '.join(obj.get('tags', []))}",
            "é£Ÿæ:",
            "\n".join(
                f"  - {ing.get('name', '')}ï¼š{ing.get('amount', '')}"
                for ing in (obj.get("ingredients") or [])
            ),
            "æ­¥é©Ÿ:",
            "\n".join(
                f"  {k}. {v}"
                for k, v in sorted((obj.get("steps") or {}).items(), key=lambda x: int(x[0]))
            ),
        ]
        page_content = "\n".join(content_parts)
        metadata = meta_func(obj, seq_num=i)
        docs.append(Document(page_content=page_content, metadata=metadata))
    return docs


def docs_store_chroma(docs: List[Document]) -> Chroma:
    # splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")
    
    vectordb = Chroma.from_documents(
        documents=docs,
        embedding=embeddings,
        # persist_directory="./recipe_chroma_db",
        collection_name="recipes"
    )
    print("âœ¨ å·²å­˜å…¥è³‡æ–™ç­†æ•¸é€²å…¥å‘é‡è³‡æ–™åº«ï¼š", vectordb._collection.count())
    return vectordb

class GraphState(TypedDict):
    question: str
    generation: str
    documents: List[str]

# å®šç¾©çµæ§‹åŒ–è©•åˆ†æ¨¡å‹
class RecipeRatingItem(BaseModel):
    title: str = Field(..., description="é£Ÿè­œåç¨±")
    score: int = Field(..., ge=1, le=3, description="é£Ÿè­œè©•åˆ†ï¼Œ1 åˆ° 3 åˆ†")
    reason: str = Field(..., description="çµ¦å‡ºé€™å€‹è©•åˆ†çš„ç°¡çŸ­ç†ç”±")
    image_url: str = Field("", description="é£Ÿè­œåœ–ç‰‡çš„ç¶²å€")
    recipe_link: str = Field("", description="é£Ÿè­œåŸå§‹é€£çµ")

    class Config:
        extra = "allow"

class RecipeRatings(BaseModel):
    ratings: List[RecipeRatingItem]

def build_workflow(vectorstore: Chroma, k: int):
    llm = init_chat_model(model_name, model_provider="groq")
    retriever = vectorstore.as_retriever(search_kwargs={"k": k})  # å–å‰ k ç­†

    system_prompt = """
    ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é£Ÿè­œåˆ†æå¸«ï¼Œç†Ÿæ‚‰å„é¡é£Ÿæèˆ‡çƒ¹é£ªæŠ€å·§ã€‚  
    è«‹æ ¹æ“šä½¿ç”¨è€…æä¾›çš„æ¢ä»¶ï¼Œç‚ºæª¢ç´¢åˆ°çš„æ¯é“é£Ÿè­œæ‰“åˆ†ï¼ˆ1~3 åˆ†ï¼Œ1 ä»£è¡¨ä¸ç¬¦åˆï¼Œ2 ä»£è¡¨éƒ¨åˆ†ç¬¦åˆï¼Œ3 ä»£è¡¨ç¬¦åˆï¼‰ï¼Œä¸¦ç°¡è¦èªªæ˜æ‰“åˆ†çš„ç†ç”±ã€‚  
    åªè¦æœ‰é—œè¯éƒ½å±¬æ–¼éƒ¨åˆ†ç¬¦åˆï¼Œå°æ–¼ç¬¦åˆæ¢ä»¶ä¸å¿…å¤ªåš´è¬¹ã€‚
    åˆ†æ•¸è¶Šé«˜ä»£è¡¨è¶Šç¬¦åˆæ¢ä»¶ï¼Œä¸é ˆåˆ†æèˆ‡æ¢ä»¶ç„¡é—œçš„å…§å®¹ã€‚  
    è«‹åªå›å‚³ JSON æ ¼å¼ï¼Œå…§å®¹åŒ…å« titleï¼ˆé£Ÿè­œåç¨±ï¼‰ã€scoreï¼ˆåˆ†æ•¸ï¼‰ã€reasonï¼ˆç†ç”±ï¼‰ã€‚  
    è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ç†ç”±ã€‚
    """

    user_prompt = """
    ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…çš„è©•åˆ†æ¢ä»¶ï¼š{question}

    è«‹æ ¹æ“šé€™äº›æ¢ä»¶ï¼Œé–±è®€ä»¥ä¸‹é£Ÿè­œå…§å®¹ä¸¦é€²è¡Œè©•åˆ†ï¼Œä¸¦çµ¦å‡ºç°¡çŸ­ç†ç”±ã€‚
    ï¼ˆ1~3 åˆ†ï¼Œ1 ä»£è¡¨ä¸ç¬¦åˆï¼Œ2 ä»£è¡¨éƒ¨åˆ†ç¬¦åˆï¼Œ3 ä»£è¡¨ç¬¦åˆï¼‰
    åˆ†æ•¸è¶Šé«˜ä»£è¡¨è¶Šç¬¦åˆæ¢ä»¶ï¼Œä¸é ˆåˆ†æèˆ‡æ¢ä»¶ç„¡é—œçš„å…§å®¹ï¼š

    {recipe_content}

    è«‹åªå›å‚³ JSON æ ¼å¼ï¼Œå…§å®¹åŒ…å«scoreï¼ˆåˆ†æ•¸ï¼‰ã€reasonï¼ˆç†ç”±ï¼‰ã€‚  
    è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ç†ç”±ã€‚
    """

    # è©•åˆ†ç”¨ Prompt
    rating_prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("user", user_prompt)
    ])

    rating_chain = rating_prompt | llm.with_structured_output(RecipeRatingItem)

    workflow = StateGraph(GraphState)

    def retrieve(state):
        print("---æª¢ç´¢æ–‡ä»¶ä¸­---")
        question = state["question"]
        documents = retriever.invoke(question)
        return {"documents": documents, "question": question}

    def generate(state):
        print("---è©•åˆ†ä¸­---")
        documents = state["documents"]
        ratings = []

        for doc in documents:
            recipe_content = doc.page_content
            title = doc.metadata.get("recipe_name", "æœªçŸ¥é£Ÿè­œ")
            image_url = doc.metadata.get("image_url", "")
            recipe_link = doc.metadata.get("recipe_link", "")  # å–å¾—é€£çµ

            try:
                result = rating_chain.invoke({
                    "title": title,
                    "recipe_content": recipe_content,
                    "question": state["question"]
                })

                if isinstance(result, RecipeRatingItem):
                    result = result.model_copy(update={
                        "title": title,
                        "image_url": image_url,
                        "recipe_link": recipe_link
                    })
                elif isinstance(result, dict):
                    result.setdefault("reason", "æ¨¡å‹æœªæä¾›ç†ç”±")
                    result = RecipeRatingItem(
                        title=title,
                        image_url=image_url,
                        recipe_link=recipe_link,
                        **result
                    )

                ratings.append(result)

            except Exception as e:
                print("è©•åˆ†å¤±æ•—ï¼š", e)
                ratings.append(RecipeRatingItem(
                    title=title,
                    score=0,
                    reason="æ¨¡å‹è©•åˆ†å¤±æ•—ï¼Œç„¡æ³•æä¾›ç†ç”±ã€‚",
                    image_url=image_url,
                    recipe_link=recipe_link
                ))


            print(f"ã€{title}ã€‘")
            print(f"â­ è©•åˆ†ï¼š{result.score}")
            print(f"ğŸ’¬ ç†ç”±ï¼š{result.reason}")
            print("=====================================")

        return {
            "documents": documents,
            "question": state["question"],
            "generation": RecipeRatings(ratings=ratings).model_dump()
        }



    workflow.add_node("retrieve", retrieve)
    workflow.add_node("generate", generate)
    workflow.add_edge(START, "retrieve")
    workflow.add_edge("retrieve", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()
